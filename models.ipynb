{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\diyac\\anaconda3\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\diyac\\anaconda3\\lib\\site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\diyac\\anaconda3\\lib\\site-packages (from xgboost) (1.11.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement xgboost.xgbclassifier (from versions: none)\n",
      "ERROR: No matching distribution found for xgboost.xgbclassifier\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost.xgbclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Metrics to use other than the accuracy (Success rate)\n",
    "# https://scikit-learn.org/stable/modules/classes.html?highlight=metric#module-sklearn.metrics\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specificity(ytest,ypred):\n",
    "    tn, fp, fn, tp = confusion_matrix(ytest,ypred).ravel()\n",
    "    spec = tn/(tn+fp)\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(model,X_train,y_train,X_test,y_test):\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    print(type(model).__name__)\n",
    "   \n",
    "    print(\"Acc:  \", model.score(X_test,y_test))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    prec = precision_score(y_test,y_pred,average=None)\n",
    "    print(\"Prec: \",prec)\n",
    "    #spec = specificity(y_test,y_pred)\n",
    "    #print(\"Spec: \", spec)\n",
    "    sens = recall_score(y_test,y_pred,average=None)\n",
    "    print(\"Sens: \", sens)\n",
    "    f1 = f1_score(y_test,y_pred,average=None)\n",
    "    print(\"F1: \",f1)\n",
    "    #res = {\"Model_Name\":type(model).__name__, \"Accuracy\": model.score(X_test,y_test),\n",
    "    #\"Precision\":prec, \"Specificity\":spec, \"Sensitivity\": sens, \"F1\":f1 }\n",
    "    res = {\"Model_Name\":type(model).__name__, \"Accuracy\": model.score(X_test,y_test),\n",
    "    \"Precision\":prec, \"Sensitivity\": sens, \"F1\":f1 }\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('data/X_TRAINING_SET_Diabetes_ENCODED.csv')\n",
    "X_test = pd.read_csv('data/X_VALIDATION_SET_ENCODED.csv')\n",
    "y_train = pd.read_csv('data/Y_TRAINING_SET_EDIT.csv')\n",
    "y_test = pd.read_csv('data/Y_VALIDATION_SET_EDIT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.drop(columns=['Unnamed: 0'])\n",
    "y_test = y_test.drop(columns=['Unnamed: 0'])\n",
    "X_train = X_train.drop(columns=['Unnamed: 0'])\n",
    "X_test = X_test.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['number_outpatient', 'number_emergency', 'number_inpatient',\n",
      "       'number_diagnoses', 'race_AfricanAmerican', 'race_Asian',\n",
      "       'race_Caucasian', 'race_Hispanic', 'race_Other', 'gender_Female',\n",
      "       'gender_Male', 'gender_Unknown/Invalid', 'age_[0-10)', 'age_[10-20)',\n",
      "       'age_[20-30)', 'age_[30-40)', 'age_[40-50)', 'age_[50-60)',\n",
      "       'age_[60-70)', 'age_[70-80)', 'age_[80-90)', 'age_[90-100)',\n",
      "       'weight_>200', 'weight_[0-25)', 'weight_[100-125)', 'weight_[125-150)',\n",
      "       'weight_[150-175)', 'weight_[175-200)', 'weight_[25-50)',\n",
      "       'weight_[50-75)', 'weight_[75-100)', 'payer_code_BC', 'payer_code_CH',\n",
      "       'payer_code_CM', 'payer_code_CP', 'payer_code_DM', 'payer_code_FR',\n",
      "       'payer_code_HM', 'payer_code_MC', 'payer_code_MD'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the column names\n",
    "print(X_train.columns[10:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = [col.replace('[', '_').replace(']', '_').replace('<', 'less_than') for col in X_train.columns]\n",
    "# Create a dictionary to map old names to new names\n",
    "column_mapping = dict(zip(X_train.columns, new_column_names))\n",
    "X_train = X_train.rename(columns=column_mapping)\n",
    "#--------\n",
    "new_column_names = [col.replace('[', '_').replace(']', '_').replace('<', 'less_than') for col in X_test.columns]\n",
    "# Create a dictionary to map old names to new names\n",
    "column_mapping = dict(zip(X_test.columns, new_column_names))\n",
    "X_test = X_test.rename(columns=column_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['number_outpatient', 'number_emergency', 'number_inpatient',\n",
      "       'number_diagnoses', 'race_AfricanAmerican', 'race_Asian',\n",
      "       'race_Caucasian', 'race_Hispanic', 'race_Other', 'gender_Female',\n",
      "       'gender_Male', 'gender_Unknown/Invalid', 'age__0-10)', 'age__10-20)',\n",
      "       'age__20-30)', 'age__30-40)', 'age__40-50)', 'age__50-60)',\n",
      "       'age__60-70)', 'age__70-80)', 'age__80-90)', 'age__90-100)',\n",
      "       'weight_>200', 'weight__0-25)', 'weight__100-125)', 'weight__125-150)',\n",
      "       'weight__150-175)', 'weight__175-200)', 'weight__25-50)',\n",
      "       'weight__50-75)', 'weight__75-100)', 'payer_code_BC', 'payer_code_CH',\n",
      "       'payer_code_CM', 'payer_code_CP', 'payer_code_DM', 'payer_code_FR',\n",
      "       'payer_code_HM', 'payer_code_MC', 'payer_code_MD'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_test.columns[10:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models\n",
    "model1 = XGBClassifier()\n",
    "model2 = RandomForestClassifier()\n",
    "model3 = AdaBoostClassifier()\n",
    "\n",
    "model4 = LogisticRegression()\n",
    "model5 = KNeighborsClassifier()\n",
    "model6 = LinearDiscriminantAnalysis()\n",
    "model7 = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "Acc:   0.6030375223347231\n",
      "Prec:  [0.64575318 0.47115385 0.51743462]\n",
      "Sens:  [0.80486905 0.04347826 0.47148936]\n",
      "F1:  [0.71658456 0.07961007 0.49339469]\n",
      "XGBClassifier\n",
      "Acc:   0.6030375223347231\n",
      "Prec:  [0.64575318 0.47115385 0.51743462]\n",
      "Sens:  [0.80486905 0.04347826 0.47148936]\n",
      "F1:  [0.71658456 0.07961007 0.49339469]\n",
      "XGBClassifier\n",
      "Acc:   0.6030375223347231\n",
      "Prec:  [0.64575318 0.47115385 0.51743462]\n",
      "Sens:  [0.80486905 0.04347826 0.47148936]\n",
      "F1:  [0.71658456 0.07961007 0.49339469]\n",
      "XGBClassifier\n",
      "Acc:   0.6030375223347231\n",
      "Prec:  [0.64575318 0.47115385 0.51743462]\n",
      "Sens:  [0.80486905 0.04347826 0.47148936]\n",
      "F1:  [0.71658456 0.07961007 0.49339469]\n",
      "XGBClassifier\n",
      "Acc:   0.6030375223347231\n",
      "Prec:  [0.64575318 0.47115385 0.51743462]\n",
      "Sens:  [0.80486905 0.04347826 0.47148936]\n",
      "F1:  [0.71658456 0.07961007 0.49339469]\n",
      "XGBClassifier\n",
      "Acc:   0.6030375223347231\n",
      "Prec:  [0.64575318 0.47115385 0.51743462]\n",
      "Sens:  [0.80486905 0.04347826 0.47148936]\n",
      "F1:  [0.71658456 0.07961007 0.49339469]\n",
      "XGBClassifier\n",
      "Acc:   0.6030375223347231\n",
      "Prec:  [0.64575318 0.47115385 0.51743462]\n",
      "Sens:  [0.80486905 0.04347826 0.47148936]\n",
      "F1:  [0.71658456 0.07961007 0.49339469]\n",
      "{'XGBClassifier': {'Model_Name': 'XGBClassifier', 'Accuracy': 0.6030375223347231, 'Precision': array([0.64575318, 0.47115385, 0.51743462]), 'Sensitivity': array([0.80486905, 0.04347826, 0.47148936]), 'F1': array([0.71658456, 0.07961007, 0.49339469])}, 'RandomForestClassifier': {'Model_Name': 'XGBClassifier', 'Accuracy': 0.6030375223347231, 'Precision': array([0.64575318, 0.47115385, 0.51743462]), 'Sensitivity': array([0.80486905, 0.04347826, 0.47148936]), 'F1': array([0.71658456, 0.07961007, 0.49339469])}, 'AdaBoostClassifier': {'Model_Name': 'XGBClassifier', 'Accuracy': 0.6030375223347231, 'Precision': array([0.64575318, 0.47115385, 0.51743462]), 'Sensitivity': array([0.80486905, 0.04347826, 0.47148936]), 'F1': array([0.71658456, 0.07961007, 0.49339469])}, 'LogisticRegression': {'Model_Name': 'XGBClassifier', 'Accuracy': 0.6030375223347231, 'Precision': array([0.64575318, 0.47115385, 0.51743462]), 'Sensitivity': array([0.80486905, 0.04347826, 0.47148936]), 'F1': array([0.71658456, 0.07961007, 0.49339469])}, 'KNeighborsClassifier': {'Model_Name': 'XGBClassifier', 'Accuracy': 0.6030375223347231, 'Precision': array([0.64575318, 0.47115385, 0.51743462]), 'Sensitivity': array([0.80486905, 0.04347826, 0.47148936]), 'F1': array([0.71658456, 0.07961007, 0.49339469])}, 'LinearDiscriminantAnalysis': {'Model_Name': 'XGBClassifier', 'Accuracy': 0.6030375223347231, 'Precision': array([0.64575318, 0.47115385, 0.51743462]), 'Sensitivity': array([0.80486905, 0.04347826, 0.47148936]), 'F1': array([0.71658456, 0.07961007, 0.49339469])}, 'SVC': {'Model_Name': 'XGBClassifier', 'Accuracy': 0.6030375223347231, 'Precision': array([0.64575318, 0.47115385, 0.51743462]), 'Sensitivity': array([0.80486905, 0.04347826, 0.47148936]), 'F1': array([0.71658456, 0.07961007, 0.49339469])}}\n"
     ]
    }
   ],
   "source": [
    "dict_models = {}\n",
    "dict_models[\"XGBClassifier\"] = results(model1,X_train,y_train,X_test,y_test)\n",
    "dict_models[\"RandomForestClassifier\"] = results(model1,X_train,y_train,X_test,y_test)\n",
    "dict_models[\"AdaBoostClassifier\"] = results(model1,X_train,y_train,X_test,y_test)\n",
    "dict_models[\"LogisticRegression\"] = results(model1,X_train,y_train,X_test,y_test)\n",
    "dict_models[\"KNeighborsClassifier\"] = results(model1,X_train,y_train,X_test,y_test)\n",
    "dict_models[\"LinearDiscriminantAnalysis\"] = results(model1,X_train,y_train,X_test,y_test)\n",
    "dict_models[\"SVC\"] = results(model1,X_train,y_train,X_test,y_test)\n",
    "\n",
    "print(dict_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier : {'Model_Name': 'XGBClassifier', 'Accuracy': 0.6030375223347231, 'Precision': array([0.64575318, 0.47115385, 0.51743462]), 'Sensitivity': array([0.80486905, 0.04347826, 0.47148936]), 'F1': array([0.71658456, 0.07961007, 0.49339469])}\n",
      "RandomForestClassifier : {'Model_Name': 'XGBClassifier', 'Accuracy': 0.6030375223347231, 'Precision': array([0.64575318, 0.47115385, 0.51743462]), 'Sensitivity': array([0.80486905, 0.04347826, 0.47148936]), 'F1': array([0.71658456, 0.07961007, 0.49339469])}\n",
      "AdaBoostClassifier : {'Model_Name': 'XGBClassifier', 'Accuracy': 0.6030375223347231, 'Precision': array([0.64575318, 0.47115385, 0.51743462]), 'Sensitivity': array([0.80486905, 0.04347826, 0.47148936]), 'F1': array([0.71658456, 0.07961007, 0.49339469])}\n",
      "LogisticRegression : {'Model_Name': 'XGBClassifier', 'Accuracy': 0.6030375223347231, 'Precision': array([0.64575318, 0.47115385, 0.51743462]), 'Sensitivity': array([0.80486905, 0.04347826, 0.47148936]), 'F1': array([0.71658456, 0.07961007, 0.49339469])}\n",
      "KNeighborsClassifier : {'Model_Name': 'XGBClassifier', 'Accuracy': 0.6030375223347231, 'Precision': array([0.64575318, 0.47115385, 0.51743462]), 'Sensitivity': array([0.80486905, 0.04347826, 0.47148936]), 'F1': array([0.71658456, 0.07961007, 0.49339469])}\n",
      "LinearDiscriminantAnalysis : {'Model_Name': 'XGBClassifier', 'Accuracy': 0.6030375223347231, 'Precision': array([0.64575318, 0.47115385, 0.51743462]), 'Sensitivity': array([0.80486905, 0.04347826, 0.47148936]), 'F1': array([0.71658456, 0.07961007, 0.49339469])}\n",
      "SVC : {'Model_Name': 'XGBClassifier', 'Accuracy': 0.6030375223347231, 'Precision': array([0.64575318, 0.47115385, 0.51743462]), 'Sensitivity': array([0.80486905, 0.04347826, 0.47148936]), 'F1': array([0.71658456, 0.07961007, 0.49339469])}\n"
     ]
    }
   ],
   "source": [
    "for key, value in dict_models.items():\n",
    "    print(key, \":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Model_Name, Accuracy, Precision, Specificity, Sensitivity, F1]\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32784\\900869941.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Model_Name'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Precision'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Specificity'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sensitivity'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'F1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mresDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mresDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mresDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mresDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mresDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5985\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5986\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5987\u001b[0m         ):\n\u001b[0;32m   5988\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5989\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "cols = ['Model_Name','Accuracy','Precision','Specificity', 'Sensitivity','F1'] \n",
    "resDF = pd.DataFrame(columns = cols)\n",
    "print(resDF.head())\n",
    "resDF = pd.concat(results(model1,X_train,y_train,X_test,y_test),ignore_index=True)\n",
    "resDF = resDF.append(results(model2,X_train,y_train,X_test,y_test),ignore_index=True)\n",
    "resDF = resDF.append(results(model3,X_train,y_train,X_test,y_test),ignore_index=True)\n",
    "resDF = resDF.append(results(model4,X_train,y_train,X_test,y_test),ignore_index=True)\n",
    "resDF = resDF.append(results(model5,X_train,y_train,X_test,y_test),ignore_index=True)\n",
    "resDF = resDF.append(results(model6,X_train,y_train,X_test,y_test),ignore_index=True)\n",
    "resDF = resDF.append(results(model7,X_train,y_train,X_test,y_test),ignore_index=True)\n",
    "resDF.to_csv('data/testingClassifiers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "59260a63518a7b1f92526c8cf5c952b378cebd6853e883151a004bcaa240186c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
