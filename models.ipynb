{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\diyac\\anaconda3\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\diyac\\anaconda3\\lib\\site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\diyac\\anaconda3\\lib\\site-packages (from xgboost) (1.11.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement xgboost.xgbclassifier (from versions: none)\n",
      "ERROR: No matching distribution found for xgboost.xgbclassifier\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost.xgbclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall scikit-learn\n",
    "!pip install scikit-learn==1.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Metrics to use other than the accuracy (Success rate)\n",
    "# https://scikit-learn.org/stable/modules/classes.html?highlight=metric#module-sklearn.metrics\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specificity(ytest,ypred):\n",
    "    tn, fp, fn, tp = confusion_matrix(ytest,ypred).ravel()\n",
    "    spec = tn/(tn+fp)\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(model,X_train,y_train,X_test,y_test):\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    print(type(model).__name__)\n",
    "   \n",
    "    print(\"Acc:  \", model.score(X_test,y_test))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    prec = precision_score(y_test,y_pred,average=None)\n",
    "    print(\"Prec: \",prec)\n",
    "    #spec = specificity(y_test,y_pred)\n",
    "    #print(\"Spec: \", spec)\n",
    "    sens = recall_score(y_test,y_pred,average=None)\n",
    "    print(\"Sens: \", sens)\n",
    "    f1 = f1_score(y_test,y_pred,average=None)\n",
    "    print(\"F1: \",f1)\n",
    "    #res = {\"Model_Name\":type(model).__name__, \"Accuracy\": model.score(X_test,y_test),\n",
    "    #\"Precision\":prec, \"Specificity\":spec, \"Sensitivity\": sens, \"F1\":f1 }\n",
    "    res = {\"Model_Name\":type(model).__name__, \"Accuracy\": model.score(X_test,y_test),\n",
    "    \"Precision\":prec, \"Sensitivity\": sens, \"F1\":f1 }\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('data/X_TRAINING_SET_Diabetes_ENCODED.csv')\n",
    "X_test = pd.read_csv('data/X_VALIDATION_SET_ENCODED.csv')\n",
    "y_train = pd.read_csv('data/Y_TRAINING_SET_EDIT.csv')\n",
    "y_test = pd.read_csv('data/Y_VALIDATION_SET_EDIT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.drop(columns=['Unnamed: 0'])\n",
    "y_test = y_test.drop(columns=['Unnamed: 0'])\n",
    "X_train = X_train.drop(columns=['Unnamed: 0'])\n",
    "X_test = X_test.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['number_outpatient', 'number_emergency', 'number_inpatient',\n",
      "       'number_diagnoses', 'race_AfricanAmerican', 'race_Asian',\n",
      "       'race_Caucasian', 'race_Hispanic', 'race_Other', 'gender_Female',\n",
      "       'gender_Male', 'gender_Unknown/Invalid', 'age_[0-10)', 'age_[10-20)',\n",
      "       'age_[20-30)', 'age_[30-40)', 'age_[40-50)', 'age_[50-60)',\n",
      "       'age_[60-70)', 'age_[70-80)', 'age_[80-90)', 'age_[90-100)',\n",
      "       'weight_>200', 'weight_[0-25)', 'weight_[100-125)', 'weight_[125-150)',\n",
      "       'weight_[150-175)', 'weight_[175-200)', 'weight_[25-50)',\n",
      "       'weight_[50-75)', 'weight_[75-100)', 'payer_code_BC', 'payer_code_CH',\n",
      "       'payer_code_CM', 'payer_code_CP', 'payer_code_DM', 'payer_code_FR',\n",
      "       'payer_code_HM', 'payer_code_MC', 'payer_code_MD'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the column names\n",
    "print(X_train.columns[10:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = [col.replace('[', '_').replace(']', '_').replace('<', 'less_than') for col in X_train.columns]\n",
    "# Create a dictionary to map old names to new names\n",
    "column_mapping = dict(zip(X_train.columns, new_column_names))\n",
    "X_train = X_train.rename(columns=column_mapping)\n",
    "#--------\n",
    "new_column_names = [col.replace('[', '_').replace(']', '_').replace('<', 'less_than') for col in X_test.columns]\n",
    "# Create a dictionary to map old names to new names\n",
    "column_mapping = dict(zip(X_test.columns, new_column_names))\n",
    "X_test = X_test.rename(columns=column_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['number_outpatient', 'number_emergency', 'number_inpatient',\n",
      "       'number_diagnoses', 'race_AfricanAmerican', 'race_Asian',\n",
      "       'race_Caucasian', 'race_Hispanic', 'race_Other', 'gender_Female',\n",
      "       'gender_Male', 'gender_Unknown/Invalid', 'age__0-10)', 'age__10-20)',\n",
      "       'age__20-30)', 'age__30-40)', 'age__40-50)', 'age__50-60)',\n",
      "       'age__60-70)', 'age__70-80)', 'age__80-90)', 'age__90-100)',\n",
      "       'weight_>200', 'weight__0-25)', 'weight__100-125)', 'weight__125-150)',\n",
      "       'weight__150-175)', 'weight__175-200)', 'weight__25-50)',\n",
      "       'weight__50-75)', 'weight__75-100)', 'payer_code_BC', 'payer_code_CH',\n",
      "       'payer_code_CM', 'payer_code_CP', 'payer_code_DM', 'payer_code_FR',\n",
      "       'payer_code_HM', 'payer_code_MC', 'payer_code_MD'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_test.columns[10:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models\n",
    "model1 = XGBClassifier()\n",
    "model2 = RandomForestClassifier()\n",
    "model3 = AdaBoostClassifier()\n",
    "model4 = LogisticRegression()\n",
    "model5 = KNeighborsClassifier()\n",
    "model6 = LinearDiscriminantAnalysis()\n",
    "model7 = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functi buildensemble(list_models, X, Y): \n",
    " #loop xi through each row of x  \n",
    "    #for k in 1 to len of list_models\n",
    "        # model = model1 \n",
    "        #predk = model.predict(xi, avg=none)\n",
    "    #row vector of 9 things add Y to the end    \n",
    "    #return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "Acc:   0.6030375223347231\n",
      "Prec:  [0.64575318 0.47115385 0.51743462]\n",
      "Sens:  [0.80486905 0.04347826 0.47148936]\n",
      "F1:  [0.71658456 0.07961007 0.49339469]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diyac\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "Acc:   0.5942028985507246\n",
      "Prec:  [0.62208271 0.48979592 0.52038547]\n",
      "Sens:  [0.84064921 0.02129547 0.39829787]\n",
      "F1:  [0.71503647 0.04081633 0.45122931]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diyac\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier\n",
      "Acc:   0.593607305936073\n",
      "Prec:  [0.62034673 0.49122807 0.51863354]\n",
      "Sens:  [0.85134637 0.02484472 0.37900709]\n",
      "F1:  [0.71771748 0.0472973  0.43796099]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diyac\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Flags' object has no attribute 'c_contiguous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m dict_models[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m=\u001b[39m results(model3,X_train,y_train,X_test,y_test)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#dict_models[4] = results(model4,X_train,y_train,X_test,y_test)  #this isn't working \u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m dict_models[\u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m=\u001b[39m results(model5,X_train,y_train,X_test,y_test) \u001b[38;5;66;03m#this isn't working\u001b[39;00m\n\u001b[0;32m      7\u001b[0m dict_models[\u001b[38;5;241m6\u001b[39m] \u001b[38;5;241m=\u001b[39m results(model6,X_train,y_train,X_test,y_test)\n\u001b[0;32m      8\u001b[0m dict_models[\u001b[38;5;241m7\u001b[39m] \u001b[38;5;241m=\u001b[39m results(model7,X_train,y_train,X_test,y_test) \u001b[38;5;66;03m#this isn't working\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m, in \u001b[0;36mresults\u001b[1;34m(model, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train,y_train)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(model)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAcc:  \u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m.\u001b[39mscore(X_test,y_test))\n\u001b[0;32m      8\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      9\u001b[0m prec \u001b[38;5;241m=\u001b[39m precision_score(y_test,y_pred,average\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:705\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[38;5;124;03m    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\u001b[39;00m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m--> 705\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(X), sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:246\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    244\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_fit_method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m ArgKminClassMode\u001b[38;5;241m.\u001b[39mis_usable_for(\n\u001b[0;32m    247\u001b[0m         X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric\n\u001b[0;32m    248\u001b[0m     ):\n\u001b[0;32m    249\u001b[0m         probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[0;32m    250\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs_2d_:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py:471\u001b[0m, in \u001b[0;36mArgKminClassMode.is_usable_for\u001b[1;34m(cls, X, Y, metric)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_usable_for\u001b[39m(\u001b[38;5;28mcls\u001b[39m, X, Y, metric) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m    450\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return True if the dispatcher can be used for the given parameters.\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \n\u001b[0;32m    452\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m    True if the PairwiseDistancesReduction can be used, else False.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 471\u001b[0m         ArgKmin\u001b[38;5;241m.\u001b[39mis_usable_for(X, Y, metric)\n\u001b[0;32m    472\u001b[0m         \u001b[38;5;66;03m# TODO: Support CSR matrices.\u001b[39;00m\n\u001b[0;32m    473\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(X)\n\u001b[0;32m    474\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(Y)\n\u001b[0;32m    475\u001b[0m         \u001b[38;5;66;03m# TODO: implement Euclidean specialization with GEMM.\u001b[39;00m\n\u001b[0;32m    476\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m metric \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqeuclidean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    477\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py:115\u001b[0m, in \u001b[0;36mBaseDistancesReductionDispatcher.is_usable_for\u001b[1;34m(cls, X, Y, metric)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_valid_sparse_matrix\u001b[39m(X):\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    103\u001b[0m         isspmatrix_csr(X)\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    110\u001b[0m         X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mint32\n\u001b[0;32m    111\u001b[0m     )\n\u001b[0;32m    113\u001b[0m is_usable \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    114\u001b[0m     get_config()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menable_cython_pairwise_dist\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (is_numpy_c_ordered(X) \u001b[38;5;129;01mor\u001b[39;00m is_valid_sparse_matrix(X))\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (is_numpy_c_ordered(Y) \u001b[38;5;129;01mor\u001b[39;00m is_valid_sparse_matrix(Y))\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m Y\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01min\u001b[39;00m (np\u001b[38;5;241m.\u001b[39mfloat32, np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_metrics()\n\u001b[0;32m    120\u001b[0m )\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_usable\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py:99\u001b[0m, in \u001b[0;36mBaseDistancesReductionDispatcher.is_usable_for.<locals>.is_numpy_c_ordered\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_numpy_c_ordered\u001b[39m(X):\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflags\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m X\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Flags' object has no attribute 'c_contiguous'"
     ]
    }
   ],
   "source": [
    "dict_models = {}\n",
    "dict_models[1] = results(model1,X_train,y_train,X_test,y_test)\n",
    "dict_models[2] = results(model2,X_train,y_train,X_test,y_test)\n",
    "dict_models[3] = results(model3,X_train,y_train,X_test,y_test)\n",
    "#dict_models[4] = results(model4,X_train,y_train,X_test,y_test)  #this isn't working \n",
    "dict_models[5] = results(model5,X_train,y_train,X_test,y_test) #this isn't working\n",
    "dict_models[6] = results(model6,X_train,y_train,X_test,y_test)\n",
    "dict_models[7] = results(model7,X_train,y_train,X_test,y_test) #this isn't working\n",
    "\n",
    "print(dict_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_Name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.603038</td>\n",
       "      <td>[0.6457531814146197, 0.47115384615384615, 0.51...</td>\n",
       "      <td>[0.8048690520103283, 0.043478260869565216, 0.4...</td>\n",
       "      <td>[0.716584564860427, 0.07961007311129165, 0.493...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.597677</td>\n",
       "      <td>[0.6237569813376924, 0.4473684210526316, 0.528...</td>\n",
       "      <td>[0.8445223164883807, 0.015084294587400177, 0.4...</td>\n",
       "      <td>[0.7175428974379066, 0.029184549356223173, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.593607</td>\n",
       "      <td>[0.6203467275903777, 0.49122807017543857, 0.51...</td>\n",
       "      <td>[0.8513463666543711, 0.024844720496894408, 0.3...</td>\n",
       "      <td>[0.7177174842571717, 0.04729729729729729, 0.43...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.541493</td>\n",
       "      <td>[0.5528437080161218, 0.0, 0.45271453590192645]</td>\n",
       "      <td>[0.9107340464773146, 0.0, 0.14666666666666667]</td>\n",
       "      <td>[0.6880312108123171, 0.0, 0.22155560317120201]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.574251</td>\n",
       "      <td>[0.593423019431988, 0.3851851851851852, 0.5070...</td>\n",
       "      <td>[0.8786425673183327, 0.04614019520851819, 0.27...</td>\n",
       "      <td>[0.7084014869888476, 0.08240887480190175, 0.35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.541096</td>\n",
       "      <td>[0.5471076137813696, 0.0, 0.45671641791044776]</td>\n",
       "      <td>[0.948911840649207, 0.0, 0.08680851063829788]</td>\n",
       "      <td>[0.6940509915014165, 0.0, 0.14588796185935637]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model_Name  Accuracy  \\\n",
       "1               XGBClassifier  0.603038   \n",
       "2      RandomForestClassifier  0.597677   \n",
       "3          AdaBoostClassifier  0.593607   \n",
       "4          LogisticRegression  0.541493   \n",
       "6  LinearDiscriminantAnalysis  0.574251   \n",
       "7                         SVC  0.541096   \n",
       "\n",
       "                                           Precision  \\\n",
       "1  [0.6457531814146197, 0.47115384615384615, 0.51...   \n",
       "2  [0.6237569813376924, 0.4473684210526316, 0.528...   \n",
       "3  [0.6203467275903777, 0.49122807017543857, 0.51...   \n",
       "4     [0.5528437080161218, 0.0, 0.45271453590192645]   \n",
       "6  [0.593423019431988, 0.3851851851851852, 0.5070...   \n",
       "7     [0.5471076137813696, 0.0, 0.45671641791044776]   \n",
       "\n",
       "                                         Sensitivity  \\\n",
       "1  [0.8048690520103283, 0.043478260869565216, 0.4...   \n",
       "2  [0.8445223164883807, 0.015084294587400177, 0.4...   \n",
       "3  [0.8513463666543711, 0.024844720496894408, 0.3...   \n",
       "4     [0.9107340464773146, 0.0, 0.14666666666666667]   \n",
       "6  [0.8786425673183327, 0.04614019520851819, 0.27...   \n",
       "7      [0.948911840649207, 0.0, 0.08680851063829788]   \n",
       "\n",
       "                                                  F1  \n",
       "1  [0.716584564860427, 0.07961007311129165, 0.493...  \n",
       "2  [0.7175428974379066, 0.029184549356223173, 0.4...  \n",
       "3  [0.7177174842571717, 0.04729729729729729, 0.43...  \n",
       "4     [0.6880312108123171, 0.0, 0.22155560317120201]  \n",
       "6  [0.7084014869888476, 0.08240887480190175, 0.35...  \n",
       "7     [0.6940509915014165, 0.0, 0.14588796185935637]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(dict_models, orient='index')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier : {'Model_Name': 'XGBClassifier', 'Accuracy': 0.6030375223347231, 'Precision': array([0.64575318, 0.47115385, 0.51743462]), 'Sensitivity': array([0.80486905, 0.04347826, 0.47148936]), 'F1': array([0.71658456, 0.07961007, 0.49339469])}\n",
      "RandomForestClassifier : {'Model_Name': 'XGBClassifier', 'Accuracy': 0.6030375223347231, 'Precision': array([0.64575318, 0.47115385, 0.51743462]), 'Sensitivity': array([0.80486905, 0.04347826, 0.47148936]), 'F1': array([0.71658456, 0.07961007, 0.49339469])}\n",
      "AdaBoostClassifier : {'Model_Name': 'XGBClassifier', 'Accuracy': 0.6030375223347231, 'Precision': array([0.64575318, 0.47115385, 0.51743462]), 'Sensitivity': array([0.80486905, 0.04347826, 0.47148936]), 'F1': array([0.71658456, 0.07961007, 0.49339469])}\n",
      "LogisticRegression : {'Model_Name': 'XGBClassifier', 'Accuracy': 0.6030375223347231, 'Precision': array([0.64575318, 0.47115385, 0.51743462]), 'Sensitivity': array([0.80486905, 0.04347826, 0.47148936]), 'F1': array([0.71658456, 0.07961007, 0.49339469])}\n",
      "KNeighborsClassifier : {'Model_Name': 'XGBClassifier', 'Accuracy': 0.6030375223347231, 'Precision': array([0.64575318, 0.47115385, 0.51743462]), 'Sensitivity': array([0.80486905, 0.04347826, 0.47148936]), 'F1': array([0.71658456, 0.07961007, 0.49339469])}\n",
      "LinearDiscriminantAnalysis : {'Model_Name': 'XGBClassifier', 'Accuracy': 0.6030375223347231, 'Precision': array([0.64575318, 0.47115385, 0.51743462]), 'Sensitivity': array([0.80486905, 0.04347826, 0.47148936]), 'F1': array([0.71658456, 0.07961007, 0.49339469])}\n",
      "SVC : {'Model_Name': 'XGBClassifier', 'Accuracy': 0.6030375223347231, 'Precision': array([0.64575318, 0.47115385, 0.51743462]), 'Sensitivity': array([0.80486905, 0.04347826, 0.47148936]), 'F1': array([0.71658456, 0.07961007, 0.49339469])}\n"
     ]
    }
   ],
   "source": [
    "for key, value in dict_models.items():\n",
    "    print(key, \":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Model_Name, Accuracy, Precision, Specificity, Sensitivity, F1]\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32784\\900869941.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Model_Name'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Precision'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Specificity'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sensitivity'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'F1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mresDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mresDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mresDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mresDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mresDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5985\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5986\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5987\u001b[0m         ):\n\u001b[0;32m   5988\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5989\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "cols = ['Model_Name','Accuracy','Precision','Specificity', 'Sensitivity','F1'] \n",
    "resDF = pd.DataFrame(columns = cols)\n",
    "print(resDF.head())\n",
    "resDF = pd.concat(results(model1,X_train,y_train,X_test,y_test),ignore_index=True)\n",
    "resDF = resDF.append(results(model2,X_train,y_train,X_test,y_test),ignore_index=True)\n",
    "resDF = resDF.append(results(model3,X_train,y_train,X_test,y_test),ignore_index=True)\n",
    "resDF = resDF.append(results(model4,X_train,y_train,X_test,y_test),ignore_index=True)\n",
    "resDF = resDF.append(results(model5,X_train,y_train,X_test,y_test),ignore_index=True)\n",
    "resDF = resDF.append(results(model6,X_train,y_train,X_test,y_test),ignore_index=True)\n",
    "resDF = resDF.append(results(model7,X_train,y_train,X_test,y_test),ignore_index=True)\n",
    "resDF.to_csv('data/testingClassifiers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "59260a63518a7b1f92526c8cf5c952b378cebd6853e883151a004bcaa240186c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
